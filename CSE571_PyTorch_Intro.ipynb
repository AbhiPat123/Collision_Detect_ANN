{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSE571_PyTorch_Intro.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlhrJ7W1sI-Y"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjzheUqr4p59"
      },
      "source": [
        "# PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YKdA44zn1zgK"
      },
      "source": [
        "BUILD A NETWORK / MODEL<br/>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;- initialize network layers<br/>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;- define function to compute forward pass<br/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCRkNQUk4rtf"
      },
      "source": [
        "# a basic NN\n",
        "class Basic_Network(nn.Module):\n",
        "    # initialize with a set of inputs, hidden and output nodes - Define Architecture\n",
        "    def __init__(self, input_size=5, hidden_size=4, output_size=2):\n",
        "        # initializing the base (super) class of this class - same as super().__init__()\n",
        "        super(Basic_Network, self).__init__()\n",
        "        # relationship between input and hidden layer - Linear Layer\n",
        "        self.input_to_hidden = nn.Linear(input_size, hidden_size)\n",
        "        # relationship between hidden and output layer - Linear Layer\n",
        "        self.hidden_to_output = nn.Linear(hidden_size, output_size)\n",
        "        # non-linear activation to use\n",
        "        self.nonlinear_activation = nn.Sigmoid()\n",
        "\n",
        "    # the forward pass from inputs to outputs - Define computation\n",
        "    def forward(self, network_input):\n",
        "        # take the network input and pass through hidden layer (no activation yet)\n",
        "        hidden = self.input_to_hidden(network_inpt)\n",
        "        # apply nonlinear activation on the previous computation\n",
        "        hidden = self.nonlinear_activation(hidden)\n",
        "        # pass the output of hidden layer through the final/output layer\n",
        "        network_output = self.hidden_to_output(hidden)\n",
        "        # return the network output value\n",
        "        return network_output"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ca97noIe9_35"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;- build a basic_model object for network<br/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDkRMAUT0ujp"
      },
      "source": [
        "# create a model with default numbers of neurons for our Basic Network\n",
        "basic_model = Basic_Network()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQ3Q4fjM-ANo"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;- perform forward pass on the model<br/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "id": "5gbwBg391E1Q",
        "outputId": "ac0e38b6-9eed-41ec-dc44-6e9f5e5f2c46"
      },
      "source": [
        "# compute networkoutput for a specific input\n",
        "network_input = \n",
        "network_output = basic_model(network_input)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-0f9074fbec6d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    network_input =\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xVu-RBv5pFo"
      },
      "source": [
        "TRAIN MODEL<br/>\n",
        "&nbsp;&nbsp;&nbsp;&nbsp;- define a learning rate, optimizer and loss function<br/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9nqE2QV-Pbv"
      },
      "source": [
        "# set a learning rate\n",
        "learning_rate = 0.01\n",
        "\n",
        "# set an optimizer to use - pass the basic_model.parameters()\n",
        "optimizer = torch.optim.SGD(basic_model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Loss Function takes (output, target) pair and finds loss for those values\n",
        "loss_function = nn.MSELoss()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0HEPrB4-P7f"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;- reset to zero for the parameters' gradients<br/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "1vbd3vS5-QSw",
        "outputId": "6294a769-0b90-4f36-c0c9-c764345d8cee"
      },
      "source": [
        "# zero out all parameters' gradient values - before performing every step of backward\n",
        "# NOTE: this is important because the backward() function acumulates gradients and does not overwrite it\n",
        "optimizer.zero_grad()\n",
        "\n",
        "# recomputing forard pass here (to keep consistency in steps performed)\n",
        "network_output = basic_model(network_input)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-63e12916ff5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# recomputing forard pass here (to keep consistency in steps performed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mnetwork_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbasic_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'network_input' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLrBWRlv-Qxw"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;- compute loss<br/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "fL6hyIOb-RFB",
        "outputId": "526827d5-4c10-40a6-8450-803a784a6bda"
      },
      "source": [
        "# compute the loss between two sets of values - outputs and targets\n",
        "loss = loss_function(network_output, target_output)\n",
        "# print the loss value\n",
        "print(loss.item())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-498762839905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# compute the loss between two sets of values - outputs and targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# print the loss value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'network_output' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEq22JeI-RZq"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;- perform backward on the loss<br/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "id": "dbreZ3N6-bk5",
        "outputId": "98efbb91-94b1-4926-fdf6-387d4428a4e7"
      },
      "source": [
        "# run one step of the BP Algorthm\n",
        "# this accummulates the gradients value of each parameter in the parameters' .grad field\n",
        "loss.backward()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-843fd882fb30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run one step of the BP Algorthm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# this accummulates the gradients value of each parameter in the parameters' .grad field\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIsKPzL1-cD3"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;- use optimizer's step function to update paramters<br/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQysAPjU-cfg"
      },
      "source": [
        "# run one step of optimizer (one step of Gradient Descent) - actually updates the parameters\n",
        "optimizer.step()"
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}